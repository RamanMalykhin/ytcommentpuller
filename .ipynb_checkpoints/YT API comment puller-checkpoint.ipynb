{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBx_ph88RZrEHhj2-y09HNal33j_9LwjgE\n"
     ]
    }
   ],
   "source": [
    "#API package import and key input\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "api_key = input()\n",
    "\n",
    "    \n",
    "youtube = build('youtube','v3',developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hBO5olzZVZY\n"
     ]
    }
   ],
   "source": [
    "#video ID input\n",
    "ytid = input()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this will store paginated toplevel comment json dictionaries\n",
    "dictlist = []\n",
    "\n",
    "#this makes the initial request for toplevel comments, if there is more than 100 comments it will have a nextPageToken\n",
    "dict_output = youtube.commentThreads().list(part=\"snippet,replies\", videoId=ytid, maxResults = 100).execute()\n",
    "dictlist.append(dict_output)\n",
    "npt = dict_output.get('nextPageToken')\n",
    "\n",
    "#this keeps requesting new jsons with new nextPageTokens as long as the last json requested had one\n",
    "while npt:\n",
    "    dict_output = youtube.commentThreads().list(part=\"snippet,replies\", videoId=ytid, pageToken = npt, maxResults = 100).execute()\n",
    "    dictlist.append(dict_output)\n",
    "    npt = dict_output.get('nextPageToken')\n",
    "\n",
    "#this will store the actual output\n",
    "comments = []  \n",
    "\n",
    "#we loop through all output jsons and enter every thread (thread = toplevel comment)\n",
    "for dict in dictlist:\n",
    "    for thread in dict['items']:\n",
    "        onecomment = []\n",
    "        #this takes the actual text of the comment and puts it into its own little list\n",
    "        #reads the number of replies to the comment too\n",
    "        commenttext = thread['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        replycount = thread['snippet']['totalReplyCount']\n",
    "        onecomment.append(commenttext)\n",
    "        \n",
    "        #if the toplevel comment has replies, we'll need to request them\n",
    "        if replycount>0:\n",
    "            targettoplevelid = thread['snippet']['topLevelComment']['id']\n",
    "            replydictlist = []\n",
    "            #same logic as with toplevel comments\n",
    "            #request initial 100 replies, if the json came back with a nextPageToken request again\n",
    "            #keep requesting until json comes back without a nextPageToken\n",
    "            reply_dict_output = youtube.comments().list(part=\"snippet\", parentId = targettoplevelid, maxResults = 100).execute()\n",
    "            replydictlist.append(reply_dict_output)\n",
    "            replynpt = reply_dict_output.get('nextPageToken')\n",
    "            while replynpt:\n",
    "                reply_dict_output = youtube.comments().list(part=\"snippet\", parentId = targettoplevelid, pageToken = replynpt, maxResults = 100).execute()\n",
    "                replydictlist.append(reply_dict_output)\n",
    "                replynpt = reply_dict_output.get('nextPageToken')\n",
    "            #loops through reply jsons, takes the actual text of the reply and puts it into yet another list\n",
    "            #I guess I really like lists\n",
    "            parsedreplies = []\n",
    "            for replydict in replydictlist:\n",
    "                for comment in replydict['items']:\n",
    "                    parsedreplies.append(comment['snippet']['textOriginal'])\n",
    "            onecomment.append(parsedreplies)\n",
    "            #this appends to the output with the comment\n",
    "            #the output it structured like this\n",
    "            #[['top level with no replies'],['top level with replies', ['reply1','reply2']], ...]\n",
    "        comments.append(onecomment)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N comments according to YT API:  287\n",
      "N comments scraped:  287\n"
     ]
    }
   ],
   "source": [
    "#testing cell - run to check if all comments were pulled\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "l = 0\n",
    "for element in comments:\n",
    "    if len(element) == 1:\n",
    "        i += 1\n",
    "    if len(element) > 1:\n",
    "        j += 1\n",
    "    if len(element) > 1:\n",
    "        l += len(element[1])       \n",
    "script_count = i+j+l\n",
    "\n",
    "video_output = youtube.videos().list(part=\"statistics\", id=ytid).execute()\n",
    "native_count = int(video_output['items'][0]['statistics']['commentCount'])\n",
    "\n",
    "print('N comments according to YT API: ', native_count)\n",
    "print('N comments scraped: ', script_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "Searched for: \" English \". Results follow.\n",
      "--------------\n",
      "Index : 4\n",
      "Top-level comment : ['Not my post but thought I&#39;d share<br>The Sardaukar language, like the Sardaukar themselves, relies on being efficient and survives on as little as possible. \\r<br>\\r<br>When I first watched this, I didn’t realize it was English, but it is.  Sort of.  Being the most brutally efficient army going, they found a way to speak it as efficiently as possible by trimming as much as they could while still being able to convey meaning. \\r<br>\\r<br>Here’s the recipe:\\r<br>-Take English\\r<br>-Get rid of 75% of the sounds and syllables. \\r<br>-Now slam what’s left together.  \\r<br>-simplify vowel sounds down to “eh”, “ah”, “ee” or oo”. \\r<br>-Speed it up by giving it an almost superhuman ability of being able to produce literally two sounds at once, sounds over sounds. \\r<br>\\r<br>“No! We are the Sardaukar!” \\r<br>“N.                 th   Sardaukar!”\\r<br>(compress and speed up)\\r<br>“nah! (Tha/Sa)daukar! \\r<br>\\r<br>“Those who stand against us fall!”\\r<br> “     se-who st-         gai-st u- falla “\\r<br>(compress and speed up)\\r<br>“suh-oost-ageesta-fallah”\\r<br>\\r<br>\\r<br>“It is done”\\r<br>“It  s-d-\\r<br>“Et’sa-duh”\\r<br>\\r<br>The only word they don’t shorten is “Sardaukar”.   \\r<br>Which is badass. They let that stay long.  \\r<br>Maybe it’s already a shortened version of something originally bigger. \\r<br>\\r<br>The people who worked on this movie are next level.']\n",
      "Replies : 7\n",
      "--------------\n",
      "Index : 17\n",
      "Top-level comment : ['I’m new to Dune lore… Does anyone know why the film opens with that line in Sardaukar, as opposed to in English? Was it a story choice, or was it an artistic one?']\n",
      "Replies : 7\n",
      "--------------\n",
      "Index : 54\n",
      "Top-level comment : ['I love the language. How aggressive and intimidating it sounds. It doesn&#39;t flow like other languages do; it cuts off abruptly. Almost sounds like the sounds a machine or a computer makes.']\n",
      "Replies : 13\n",
      "--------------\n",
      "Index : 76\n",
      "Top-level comment : ['Mongolian throat singing and it was interesting choice. You could go deeper. The Sardukar are more or less Dune&#39;s version of the Turkish Janissary. Captive boys made into elite to fight for the Sultan...or in this case the Empeor. Turks are cousins to the Mongols. Turkic people. So did Denis know this?']\n",
      "Replies : 22\n",
      "--------------\n",
      "Index : 83\n",
      "Top-level comment : ['The one time where pretty obvious foreshadowing went unnoticed by most. Even myself.']\n",
      "Replies : 7\n",
      "--------------\n",
      "Index : 100\n",
      "Top-level comment : ['Glad someone else noticed the first line of the chant was the line from the beginning of the film']\n",
      "Replies : 26\n"
     ]
    }
   ],
   "source": [
    "#search toplevels\n",
    "import fnmatch\n",
    "searchterm = input()\n",
    "pattern = '*'+searchterm+'*'\n",
    "\n",
    "results = []\n",
    "i = -1\n",
    "        \n",
    "for commentthread in comments:\n",
    "    i += 1\n",
    "    if len(commentthread) > 1:\n",
    "        toplevel = commentthread[0]\n",
    "        flatthread = commentthread[1]\n",
    "        flatthread.append(toplevel)\n",
    "        if len(fnmatch.filter(flatthread,pattern))>0:\n",
    "            resulttoplevel = commentthread[0]\n",
    "            numofreplies = len(commentthread[1])\n",
    "            results.append([i,[resulttoplevel],numofreplies])\n",
    "    else:\n",
    "        if fnmatch.fnmatch(commentthread[0],pattern):\n",
    "            resulttoplevel = commentthread[0]\n",
    "            numofreplies = 0\n",
    "            results.append([i,[resulttoplevel],numofreplies])\n",
    "    \n",
    "        \n",
    "        \n",
    "print('Searched for: \\\"', searchterm, '\\\". Results follow.')\n",
    "if len(results)>0:\n",
    "    for result in results:\n",
    "        print('--------------')\n",
    "        print('Index :', result[0])\n",
    "        print('Top-level comment :', result[1])\n",
    "        print('Replies :', result[2])\n",
    "else:\n",
    "    print('--------------')\n",
    "    print('No results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
