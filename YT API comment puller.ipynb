{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YT API KEY GOES HERE\n"
     ]
    }
   ],
   "source": [
    "#API package import and key input\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "api_key = input()\n",
    "\n",
    "    \n",
    "youtube = build('youtube','v3',developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIDEO ID GOES HERE\n"
     ]
    }
   ],
   "source": [
    "#video ID input\n",
    "ytid = input()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this will store paginated toplevel comment json dictionaries\n",
    "dictlist = []\n",
    "\n",
    "#this makes the initial request for toplevel comments, if there is more than 100 comments it will have a nextPageToken\n",
    "dict_output = youtube.commentThreads().list(part=\"snippet,replies\", videoId=ytid, maxResults = 100).execute()\n",
    "dictlist.append(dict_output)\n",
    "npt = dict_output.get('nextPageToken')\n",
    "\n",
    "#this keeps requesting new jsons with new nextPageTokens as long as the last json requested had one\n",
    "while npt:\n",
    "    dict_output = youtube.commentThreads().list(part=\"snippet,replies\", videoId=ytid, pageToken = npt, maxResults = 100).execute()\n",
    "    dictlist.append(dict_output)\n",
    "    npt = dict_output.get('nextPageToken')\n",
    "\n",
    "#this will store the actual output\n",
    "comments = []  \n",
    "\n",
    "#we loop through all output jsons and enter every thread (thread = toplevel comment)\n",
    "for dict in dictlist:\n",
    "    for thread in dict['items']:\n",
    "        onecomment = []\n",
    "        #this takes the actual text of the comment and puts it into its own little list\n",
    "        #reads the number of replies to the comment too\n",
    "        commenttext = thread['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        replycount = thread['snippet']['totalReplyCount']\n",
    "        onecomment.append(commenttext)\n",
    "        \n",
    "        #if the toplevel comment has replies, we'll need to request them\n",
    "        if replycount>0:\n",
    "            targettoplevelid = thread['snippet']['topLevelComment']['id']\n",
    "            replydictlist = []\n",
    "            #same logic as with toplevel comments\n",
    "            #request initial 100 replies, if the json came back with a nextPageToken request again\n",
    "            #keep requesting until json comes back without a nextPageToken\n",
    "            reply_dict_output = youtube.comments().list(part=\"snippet\", parentId = targettoplevelid, maxResults = 100).execute()\n",
    "            replydictlist.append(reply_dict_output)\n",
    "            replynpt = reply_dict_output.get('nextPageToken')\n",
    "            while replynpt:\n",
    "                reply_dict_output = youtube.comments().list(part=\"snippet\", parentId = targettoplevelid, pageToken = replynpt, maxResults = 100).execute()\n",
    "                replydictlist.append(reply_dict_output)\n",
    "                replynpt = reply_dict_output.get('nextPageToken')\n",
    "            #loops through reply jsons, takes the actual text of the reply and puts it into yet another list\n",
    "            #I guess I really like lists\n",
    "            parsedreplies = []\n",
    "            for replydict in replydictlist:\n",
    "                for comment in replydict['items']:\n",
    "                    parsedreplies.append(comment['snippet']['textOriginal'])\n",
    "            onecomment.append(parsedreplies)\n",
    "            #this appends to the output with the comment\n",
    "            #the output it structured like this\n",
    "            #[['top level with no replies'],['top level with replies', ['reply1','reply2']], ...]\n",
    "  \n",
    "\n",
    "        comments.append(onecomment)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9008"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing cell - run to check if all comments were pulled\n",
    "#number should be equal or within 1-2 of the number on the YT video page\n",
    "#YT counters are occasionally inaccurate\n",
    "\n",
    "i = 0\n",
    "for element in comments:\n",
    "    if len(element) == 1:\n",
    "        i += 1\n",
    " \n",
    "j = 0\n",
    "for element in comments:\n",
    "    if len(element) > 1:\n",
    "        j += 1\n",
    "\n",
    "l = 0\n",
    "for element in comments:\n",
    "    if len(element) > 1:\n",
    "        l += len(element[1])\n",
    "        \n",
    "i+j+l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
